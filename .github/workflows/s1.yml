name: ðŸš€ Ultra-Fast Stock Scraper (500 Symbols)

on:
  workflow_dispatch:
    inputs:
      start_index:
        description: 'Start Index'
        required: true
        default: '0'
        type: number
      end_index:
        description: 'End Index (500 recommended)'
        required: true
        default: '500'
        type: number
  schedule:
    - cron: '0 2 * * 1-5'  # Mon-Fri 2AM UTC

env:
  START_INDEX: ${{ github.event.inputs.start_index || 0 }}
  END_INDEX: ${{ github.event.inputs.end_index || 500 }}
  MAX_WORKERS: 8

jobs:
  scrape-fast:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Install Dependencies
      run: |
        pip install gspread oauth2client selenium beautifulsoup4 webdriver-manager
        
    - name: Setup Chrome & Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable xvfb libnss3 libgconf-2-4 libxss1 libasound2
        
    - name: Run Fast Scraper
      env:
        GSPREAD_CREDENTIALS: ${{ secrets.GSPREAD_CREDENTIALS }}
        MAX_WORKERS: 8
      run: |
        python run_scraper.py
        
    - name: Upload Checkpoint & Logs
      uses: actions/upload-artifact@v4
      with:
        name: scraper-results
        path: |
          fast_checkpoint.txt
          *.log
        retention-days: 7
        
    - name: Success Summary
      if: success()
      run: |
        echo "ðŸŽ‰ ULTRA-FAST SCRAPER COMPLETE!"
        echo "âœ… 500 symbols processed successfully"
        echo "ðŸ“Š Check Sheet5 for results"
