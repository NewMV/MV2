name: TradingView Scraper Batch 2

on:
  workflow_dispatch:
  schedule:
    - cron: '30 0 * * *'   # runs daily, offset from batch 1

jobs:
  scrape_and_upload:
    runs-on: ubuntu-latest

    strategy:
      fail-fast: false
      matrix:
        shard: [10,11,12,13,14,15,16,17,18,19]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas requests gspread selenium beautifulsoup4 openpyxl webdriver-manager

      - name: Create credentials & cookies
        run: |
          echo "$GSPREAD_CREDENTIALS" > credentials.json
          echo "$TRADINGVIEW_COOKIES" > cookies.json
        env:
          GSPREAD_CREDENTIALS: ${{ secrets.GSPREAD_CREDENTIALS }}
          TRADINGVIEW_COOKIES: ${{ secrets.TRADINGVIEW_COOKIES }}

      - name: Run scraper (Shard ${{ matrix.shard }})
        run: |
          export PYTHONUNBUFFERED=1
          python run_scraper.py
        env:
          START_INDEX: 1
          END_INDEX: 2500
          SHARD_INDEX: ${{ matrix.shard }}
          SHARD_STEP: 40
