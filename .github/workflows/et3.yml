name: ET Money 1000-1499
on: [workflow_dispatch, schedule: {cron: '0 6 * * 1'}]
env: {CHUNK_START: 1000, CHUNK_END: 1499}
jobs: # [SAME as above - just change env CHUNK_START/END]
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    steps: # [IDENTICAL steps as chunk-0-499]
    - uses: actions/checkout@v4
    - uses: actions/setup-python@v5
      with: {python-version: '3.11'}
    - run: |
        sudo apt-get update -qq && sudo apt-get install -y google-chrome-stable xvfb wget unzip
    - run: pip install gspread selenium beautifulsoup4 webdriver-manager oauth2client
    - run: |
        echo '${{ secrets.GSPREAD_CREDENTIALS }}' > credentials.json
        python -c "import json; json.load(open('credentials.json'))"
    - run: python etmoney_scraper.py
      env: {CHUNK_START: ${{ env.CHUNK_START }}, CHUNK_END: ${{ env.CHUNK_END }}}
    - if: always()
      uses: actions/upload-artifact@v4
      with:
        name: sectors-1000-1499-${{ github.run_id }}
        path: | 
          chunk_*.csv
          *.log
        retention-days: 30
